{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "# 高维线性回归，以展示过拟合的效果\n",
    "class Data(d2l.DataModule):\n",
    "    def __init__(self, num_train, num_val, num_inputs, batch_size):\n",
    "        self.save_hyperparameters()\n",
    "        n = num_train + num_val\n",
    "        self.X = torch.randn(n, num_inputs)\n",
    "        noise = torch.randn(n, 1) * 0.01  # 噪声为符合均值为0，标准差为0.01的正态分布的随机数\n",
    "        w, b = torch.ones((num_inputs, 1)) * 0.01, 0.05  # 权重向量 w 和偏差 b，请看教程中的公式\n",
    "        self.y = torch.matmul(self.X, w) + b + noise\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
    "        return self.get_tensorloader([self.X, self.y], train, i)\n",
    "\n",
    "\n",
    "# 定义范数惩罚\n",
    "def l2_penalty(w):\n",
    "    return (w ** 2).sum() / 2\n",
    "\n",
    "\n",
    "# 定义模型，与之前的线性回归相比，这里添加了L2范数惩罚项\n",
    "class WeightDecayScratch(d2l.LinearRegressionScratch):\n",
    "    def __init__(self, num_inputs, lambd, lr, sigma=0.01):\n",
    "        super().__init__(num_inputs, lr, sigma)\n",
    "        self.save_hyperparameters()  # 保存超参数\n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        return (super().loss(y_hat, y) +\n",
    "                self.lambd * l2_penalty(self.w))  # 相比之前，加入范数惩罚项\n",
    "\n",
    "\n",
    "data = Data(num_train=20, num_val=100, num_inputs=200, batch_size=5)  # 构建数据集\n",
    "# num_train 为训练集大小，num_val 为验证集大小，num_inputs 为输入维度，batch_size 为批量大小\n",
    "trainer = d2l.Trainer(max_epochs=10)  # max_epochs 为训练轮数\n",
    "\n",
    "\n",
    "def train_scratch(lambd):  # lambd 为正则化系数，控制权重衰减强度\n",
    "    model = WeightDecayScratch(num_inputs=200, lambd=lambd, lr=0.01)  # 构建模型\n",
    "    model.board.yscale = 'log'  # 将y轴设置成对数标度\n",
    "    trainer.fit(model, data)  # 训练\n",
    "    print('L2 norm of w:', float(l2_penalty(model.w)))  # 打印权重向量的L2范数\n",
    "\n",
    "\n",
    "# 这里建议使用jupyter notebook运行，因为会输出图像\n",
    "train_scratch(0) # 不使用权重衰减，展示过拟合效果\n",
    "train_scratch(3) # 使用权重衰减，会看到训练误差增加，但是验证误差减少\n",
    "\n",
    "\n",
    "# 下面是简洁实现，使用pytorch中集成的优化器来实现\n",
    "class WeightDecay(d2l.LinearRegression):\n",
    "    def __init__(self, wd, lr):\n",
    "        super().__init__(lr) # 继承父类，初始化\n",
    "        self.save_hyperparameters()\n",
    "        self.wd = wd\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD([\n",
    "            {'params': self.net.weight, 'weight_decay': self.wd},\n",
    "            {'params': self.net.bias}], lr=self.lr)\n",
    "\n",
    "\n",
    "model = WeightDecay(wd=3, lr=0.01) # 权重衰减系数为3，学习率为0.01\n",
    "model.board.yscale = 'log'\n",
    "trainer.fit(model, data)\n",
    "\n",
    "print('L2 norm of w:', float(l2_penalty(model.get_w_b()[0])))\n"
   ],
   "id": "344694d3b987e9d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
