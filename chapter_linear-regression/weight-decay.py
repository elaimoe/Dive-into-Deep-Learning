import torch
from torch import nn
from d2l import torch as d2l


# é«˜ç»´çº¿æ€§å›å½’ï¼Œä»¥å±•ç¤ºè¿‡æ‹Ÿåˆçš„æ•ˆæœ
class Data(d2l.DataModule):
    def __init__(self, num_train, num_val, num_inputs, batch_size):
        self.save_hyperparameters()
        n = num_train + num_val
        self.X = torch.randn(n, num_inputs)
        noise = torch.randn(n, 1) * 0.01  # å™ªå£°ä¸ºç¬¦åˆå‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º0.01çš„æ­£æ€åˆ†å¸ƒçš„éšæœºæ•°
        w, b = torch.ones((num_inputs, 1)) * 0.01, 0.05  # æƒé‡å‘é‡ w å’Œåå·® bï¼Œè¯·çœ‹æ•™ç¨‹ä¸­çš„å…¬å¼
        self.y = torch.matmul(self.X, w) + b + noise

    def get_dataloader(self, train):
        i = slice(0, self.num_train) if train else slice(self.num_train, None)
        return self.get_tensorloader([self.X, self.y], train, i)


# å®šä¹‰èŒƒæ•°æƒ©ç½š
def l2_penalty(w):
    return (w ** 2).sum() / 2


# å®šä¹‰æ¨¡å‹ï¼Œä¸ä¹‹å‰çš„çº¿æ€§å›å½’ç›¸æ¯”ï¼Œè¿™é‡Œæ·»åŠ äº†L2èŒƒæ•°æƒ©ç½šé¡¹
class WeightDecayScratch(d2l.LinearRegressionScratch):
    def __init__(self, num_inputs, lambd, lr, sigma=0.01):
        super().__init__(num_inputs, lr, sigma)
        self.save_hyperparameters()  # ä¿å­˜è¶…å‚æ•°

    def loss(self, y_hat, y):
        return (super().loss(y_hat, y) +
                self.lambd * l2_penalty(self.w))  # ç›¸æ¯”ä¹‹å‰ï¼ŒåŠ å…¥èŒƒæ•°æƒ©ç½šé¡¹


data = Data(num_train=20, num_val=100, num_inputs=200, batch_size=5)  # æ„å»ºæ•°æ®é›†
# num_train ä¸ºè®­ç»ƒé›†å¤§å°ï¼Œnum_val ä¸ºéªŒè¯é›†å¤§å°ï¼Œnum_inputs ä¸ºè¾“å…¥ç»´åº¦ï¼Œbatch_size ä¸ºæ‰¹é‡å¤§å°
trainer = d2l.Trainer(max_epochs=10)  # max_epochs ä¸ºè®­ç»ƒè½®æ•°


def train_scratch(lambd):  # lambd ä¸ºæ­£åˆ™åŒ–ç³»æ•°ï¼Œæ§åˆ¶æƒé‡è¡°å‡å¼ºåº¦
    model = WeightDecayScratch(num_inputs=200, lambd=lambd, lr=0.01)  # æ„å»ºæ¨¡å‹
    model.board.yscale = 'log'  # å°†yè½´è®¾ç½®æˆå¯¹æ•°æ ‡åº¦
    trainer.fit(model, data)  # è®­ç»ƒ
    print('L2 norm of w:', float(l2_penalty(model.w)))  # æ‰“å°æƒé‡å‘é‡çš„L2èŒƒæ•°


''' # è¿™é‡Œæ¶‰åŠå¤§é‡è®¡ç®—ï¼Œå½±å“åç»­å†…å®¹ï¼Œæ•…æ³¨é‡Š
# è¿™é‡Œå»ºè®®ä½¿ç”¨jupyter notebookè¿è¡Œï¼Œå› ä¸ºä¼šè¾“å‡ºå›¾åƒ
train_scratch(0) # ä¸ä½¿ç”¨æƒé‡è¡°å‡ï¼Œå±•ç¤ºè¿‡æ‹Ÿåˆæ•ˆæœ
train_scratch(3) # ä½¿ç”¨æƒé‡è¡°å‡ï¼Œä¼šçœ‹åˆ°è®­ç»ƒè¯¯å·®å¢åŠ ï¼Œä½†æ˜¯éªŒè¯è¯¯å·®å‡å°‘
'''


# ä¸‹é¢æ˜¯ç®€æ´å®ç°ï¼Œä½¿ç”¨pytorchä¸­é›†æˆçš„ä¼˜åŒ–å™¨æ¥å®ç°
class WeightDecay(d2l.LinearRegression):
    def __init__(self, wd, lr):
        super().__init__(lr) # ç»§æ‰¿çˆ¶ç±»ï¼Œåˆå§‹åŒ–
        self.save_hyperparameters()
        self.wd = wd

    def configure_optimizers(self):
        return torch.optim.SGD([
            {'params': self.net.weight, 'weight_decay': self.wd},
            {'params': self.net.bias}], lr=self.lr)


model = WeightDecay(wd=3, lr=0.01) # æƒé‡è¡°å‡ç³»æ•°ä¸º3ï¼Œå­¦ä¹ ç‡ä¸º0.01
model.board.yscale = 'log'
trainer.fit(model, data)

print('L2 norm of w:', float(l2_penalty(model.get_w_b()[0])))


""" Exercises
1.å½“ ğœ† è¾ƒå°æ—¶ï¼Œæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°ä¼šè¾ƒå¥½ï¼Œä½†å¯èƒ½å‡ºç°è¿‡æ‹Ÿåˆï¼Œå¯¼è‡´éªŒè¯é›†ä¸Šè¡¨ç°è¾ƒå·®ã€‚
    éšç€ ğœ† å¢å¤§ï¼Œè®­ç»ƒé›†çš„è¯¯å·®å¢åŠ ï¼Œä½†éªŒè¯é›†çš„è¯¯å·®å¯èƒ½å‡å°ï¼Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æå‡ã€‚
    è¿‡å¤§çš„ ğœ† å¯èƒ½å¯¼è‡´æ¬ æ‹Ÿåˆï¼Œè®­ç»ƒå’ŒéªŒè¯é›†ä¸Šçš„è¯¯å·®éƒ½å¢å¤§ã€‚
2. é€šè¿‡éªŒè¯é›†è¯¯å·®çš„æœ€å°åŒ–å¯ä»¥æ‰¾åˆ°ä¸€ä¸ªçœ‹ä¼¼æœ€ä¼˜çš„ ğœ† å€¼ã€‚ä½†è¯¥å€¼æ˜¯å¦çœŸæ­£æœ€ä¼˜å–å†³äºæ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œ
    å¹¶ä¸”åœ¨ä¸åŒçš„æ•°æ®é›†æˆ–é—®é¢˜ä¸Šï¼Œæœ€ä¼˜å€¼å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚å› æ­¤ï¼Œå®ƒæ˜¯ä¸€ä¸ªè¿‘ä¼¼è§£ï¼Œè€Œéå”¯ä¸€è§£ã€‚
3. l1 æ­£åˆ™åŒ–çš„æ›´æ–°æ–¹ç¨‹ä¼šå¯¼è‡´æƒé‡å€¼ç¼©å‡ï¼Œå¹¶ä¸”æ¯” l2 æ›´å€¾å‘äºäº§ç”Ÿç¨€ç–è§£ï¼ˆå³éƒ¨åˆ†æƒé‡è¢«æ¨å‘ 0ï¼‰ã€‚
    å…·ä½“çš„æ¢¯åº¦ä¸‹é™æ›´æ–°è§„åˆ™ä¸­ï¼Œl1 æ­£åˆ™åŒ–ä¼šå¯¹æ¯ä¸ªæƒé‡é¡¹å¢åŠ ä¸€ä¸ªä¸ç¬¦å·ç›¸å…³çš„æ›´æ–°ï¼Œè€Œä¸åƒl2é‚£æ ·å‡åŒ€ã€‚
4. æŸ¥èµ„æ–™
5. æ•°æ®å¢å¼ºï¼šé€šè¿‡æ‰©å±•è®­ç»ƒé›†çš„å¤šæ ·æ€§ï¼Œä¾‹å¦‚ä½¿ç”¨å›¾åƒæ—‹è½¬ã€ç¿»è½¬ç­‰æ“ä½œã€‚
    Dropoutï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼Œä»¥å‡å°‘è¿‡åº¦ä¾èµ–ç‰¹å®šçš„æƒé‡ã€‚
    äº¤å‰éªŒè¯ï¼šä½¿ç”¨äº¤å‰éªŒè¯æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚
6. åœ¨è´å¶æ–¯æ¡†æ¶ä¸­ï¼Œæ­£åˆ™åŒ–å¯ä»¥è§£é‡Šä¸ºå¯¹å‚æ•°æ–½åŠ å…ˆéªŒåˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œl2 æ­£åˆ™åŒ–ç›¸å½“äºåœ¨å‚æ•°ä¸Šæ–½åŠ é«˜æ–¯å…ˆéªŒï¼Œ
    l1 æ­£åˆ™åŒ–ç›¸å½“äºæ–½åŠ æ‹‰æ™®æ‹‰æ–¯å…ˆéªŒã€‚è¿™ç§å…ˆéªŒä¼šé€šè¿‡æœ€å¤§åéªŒä¼°è®¡ï¼ˆMAPï¼‰å½±å“æŸå¤±å‡½æ•°çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚
"""
