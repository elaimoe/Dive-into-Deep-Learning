{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T15:37:23.126906Z",
     "start_time": "2024-10-31T15:37:20.522838Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import os # 解决库冲突\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8606dec0ffb5a568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T15:37:23.142524Z",
     "start_time": "2024-10-31T15:37:23.132470Z"
    }
   },
   "source": [
    "def dropout_layer(X, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    # assert: 断言是 Python 中的调试工具之一，通常用于检查代码中的某些条件。\n",
    "    # 如果条件为 True，程序继续执行；如果为 False，则会抛出一个 AssertionError，并终止程序。\n",
    "    if dropout == 1:\n",
    "        return torch.zeros_like(X)\n",
    "    mask = (torch.rand(X.shape) > dropout).float() # 这里的随机有点特别\n",
    "    return mask * X / (1.0 - dropout)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "10dcde3e-a53e-4925-9730-cbc3699713e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T15:37:23.174031Z",
     "start_time": "2024-10-31T15:37:23.159767Z"
    }
   },
   "source": [
    "X = torch.arange(16, dtype = torch.float32).reshape((2, 8))\n",
    "print('dropout_p = 0:', dropout_layer(X, 0))\n",
    "print('dropout_p = 0.5:', dropout_layer(X, 0.5))\n",
    "print('dropout_p = 1:', dropout_layer(X, 1))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout_p = 0: tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n",
      "dropout_p = 0.5: tensor([[ 0.,  2.,  4.,  0.,  8., 10., 12., 14.],\n",
      "        [16., 18., 20.,  0., 24., 26.,  0.,  0.]])\n",
      "dropout_p = 1: tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ea9b1c97-9752-417c-8027-b4e8ad625207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T15:37:23.267887Z",
     "start_time": "2024-10-31T15:37:23.251685Z"
    }
   },
   "source": [
    "class DropoutMLPScratch(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2, dropout_1, dropout_2, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lin1 = nn.LazyLinear(num_hiddens_1)\n",
    "        self.lin2 = nn.LazyLinear(num_hiddens_2)\n",
    "        self.lin3 = nn.LazyLinear(num_outputs)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        H1 = self.relu(self.lin1(X.reshape((X.shape[0], -1)))) # 内部展平\n",
    "        if self.training: # 如果在训练模式下，应用 dropout\n",
    "            H1 = dropout_layer(H1, self.dropout_1)\n",
    "        H2 = self.relu(self.lin2(H1))\n",
    "        if self.training:\n",
    "            H2 = dropout_layer(H2, self.dropout_2)\n",
    "        return self.lin3(H2)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3b185b10fd70db58",
   "metadata": {},
   "source": [
    "hparams = {'num_outputs':10, 'num_hiddens_1':256, 'num_hiddens_2':256,\n",
    "           'dropout_1':0.5, 'dropout_2':0.5, 'lr':0.1}\n",
    "model = DropoutMLPScratch(**hparams)\n",
    "data = d2l.FashionMNIST(batch_size=256)\n",
    "trainer = d2l.Trainer(max_epochs=10)\n",
    "trainer.fit(model, data)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c2533782-dc9a-40b2-b5bf-514846899245",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T15:38:50.565219Z",
     "start_time": "2024-10-31T15:38:50.551023Z"
    }
   },
   "source": [
    "# 下面开始进行简洁实现\n",
    "class DropoutMLP(d2l.Classifier):\n",
    "    def __init__(self, num_outputs, num_hiddens_1, num_hiddens_2,\n",
    "                 dropout_1, dropout_2, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential( # 这玩意实在太方便了！！\n",
    "            nn.Flatten(), nn.LazyLinear(num_hiddens_1), nn.ReLU(),\n",
    "            nn.Dropout(dropout_1), nn.LazyLinear(num_hiddens_2), nn.ReLU(),\n",
    "            nn.Dropout(dropout_2), nn.LazyLinear(num_outputs))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "7c9b9b3c-0758-4417-b376-4a59dbc87e7c",
   "metadata": {},
   "source": [
    "model = DropoutMLP(**hparams)\n",
    "trainer.fit(model, data)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\"\"\" Exercise\n",
    "1. 说实话，我没试出来有什么太大区别，但是确实最好输入层一侧调小一点，训练中可以调大一点。我看评论区推荐 0.2-0.5 的范围，感觉这玩意没什么理论呢。\n",
    "2. 增加 epoch 数量会使模型更充分地学习训练数据。使用 dropout 通常可以防止过拟合，因此在更多 epoch 后仍能保持较好的泛化性能。\n",
    "3. 使用 dropout 会增加激活值的方差，因为部分神经元的输出会随机置零。这会导致每一层的激活值分布更加分散。在不使用 dropout 的情况下，激活值的方差会相对稳定。\n",
    "4. Dropout 主要用于训练阶段以防止过拟合。在测试时，我们希望获得确定的预测，因此不再随机丢弃神经元。测试阶段的模型应该反映模型学习到的所有特征，而不是随机抑制一部分特征。\n",
    "5. Dropout 和权重衰减都用于正则化，防止过拟合。权重衰减使得权重值趋向于零，而 dropout 则随机丢弃部分神经元的输出。效果是否叠加取决于数据和模型。如果正则化太强，可能会导致模型欠拟合。\n",
    "6. 如果将 dropout 应用到权重矩阵的个别权重而不是激活值，可能会影响到参数的更新方式。这种方法可能会导致模型的训练变得不稳定，因为某些权重在某次迭代中没有更新。\n",
    "7. 一种新的方法可以是在每一层加入高斯噪声，代替 dropout。例如，可以在前向传播时加入少量的正态分布噪声，使得模型在输入数据发生轻微变化时更加鲁棒。\n",
    "\"\"\"\""
   ],
   "id": "53cca67894ac59c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
