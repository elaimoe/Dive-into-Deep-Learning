{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.610814Z",
     "start_time": "2024-11-10T03:53:04.594202Z"
    }
   },
   "source": [
    "# 由于我的电脑上没有可用的 Nvidia GPU\n",
    "# 这部分将在 https://ide.cloud.tencent.com/dashboard/gpu-workspace 中运行"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:14:06.145381Z",
     "start_time": "2024-11-19T05:14:02.746541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "id": "8a6d9ede415d5455",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.663891Z",
     "start_time": "2024-11-10T03:53:04.648506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cpu():  #@save\n",
    "    \"\"\"Get the CPU device.\"\"\"\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def gpu(i=0):  #@save\n",
    "    \"\"\"Get a GPU device.\"\"\"\n",
    "    return torch.device(f'cuda:{i}')\n",
    "\n",
    "cpu(), gpu(), gpu(1)"
   ],
   "id": "11db019f5a3605e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.694084Z",
     "start_time": "2024-11-10T03:53:04.678860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def num_gpus():  #@save\n",
    "    \"\"\"Get the number of available GPUs.\"\"\"\n",
    "    return torch.cuda.device_count()\n",
    "\n",
    "num_gpus()"
   ],
   "id": "260048ec721311ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.736153Z",
     "start_time": "2024-11-10T03:53:04.722896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
    "    if num_gpus() >= i + 1:\n",
    "        return gpu(i)\n",
    "    return cpu()\n",
    "\n",
    "def try_all_gpus():  #@save\n",
    "    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\"\"\"\n",
    "    return [gpu(i) for i in range(num_gpus())]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ],
   "id": "4e50bcc582d7b36b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'), [])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.761169Z",
     "start_time": "2024-11-10T03:53:04.752504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ],
   "id": "6656f486d2e4d8c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.790835Z",
     "start_time": "2024-11-10T03:53:04.777872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.ones(2, 3, device=try_gpu())\n",
    "X"
   ],
   "id": "392e86369f597802",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.856694Z",
     "start_time": "2024-11-10T03:53:04.839643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y = torch.rand(2, 3, device=try_gpu(1))\n",
    "Y"
   ],
   "id": "df3a293a5a426e38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0769, 0.7869, 0.3450],\n",
       "        [0.3520, 0.1784, 0.8136]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:04.927570Z",
     "start_time": "2024-11-10T03:53:04.915120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(nn.LazyLinear(1))\n",
    "net = net.to(device=try_gpu())"
   ],
   "id": "2b4953853b750653",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elaim\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:05.094170Z",
     "start_time": "2024-11-10T03:53:05.077845Z"
    }
   },
   "cell_type": "code",
   "source": "net(X)",
   "id": "84ee5a5a4b31f954",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0732],\n",
       "        [0.0732]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:53:06.009430Z",
     "start_time": "2024-11-10T03:53:05.995205Z"
    }
   },
   "cell_type": "code",
   "source": "net[0].weight.data.device",
   "id": "3fdf51496d905e57",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T03:54:03.014777Z",
     "start_time": "2024-11-10T03:54:02.998729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n",
    "    self.save_hyperparameters()\n",
    "    self.gpus = [d2l.gpu(i) for i in range(min(num_gpus, d2l.num_gpus()))]\n",
    "\n",
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def prepare_batch(self, batch):\n",
    "    if self.gpus:\n",
    "        batch = [a.to(self.gpus[0]) for a in batch]\n",
    "    return batch\n",
    "\n",
    "@d2l.add_to_class(d2l.Trainer)  #@save\n",
    "def prepare_model(self, model):\n",
    "    model.trainer = self\n",
    "    model.board.xlim = [0, self.max_epochs]\n",
    "    if self.gpus:\n",
    "        model.to(self.gpus[0])\n",
    "    self.model = model"
   ],
   "id": "98c2294626cd968d",
   "outputs": [],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
