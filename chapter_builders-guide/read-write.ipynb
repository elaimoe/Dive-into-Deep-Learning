{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T14:26:07.128953Z",
     "start_time": "2024-11-09T14:26:05.766060Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d8ee7d-4559-488d-acf9-98e9e20f0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47358f95-a849-42a7-8873-8689b4e94e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.load('x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc7aedf-c6c7-4cb7-926d-5c03a2ba8722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7211cdbd-2a40-4fcd-9908-ac2de20bdd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80efec81-c098-4789-9af9-759384a9315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elaim\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.LazyLinear(256)\n",
    "        self.output = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "564f7138-5f30-446f-affc-79fc86234634",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'mlp.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf90416-4653-4710-8541-6ae3dc6342de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): LazyLinear(in_features=0, out_features=256, bias=True)\n",
       "  (output): LazyLinear(in_features=0, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17ad95ef-c6ed-4c3e-b570-a6a8fb9225e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a89d57-342d-49b4-b3b1-d611b75798b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Exercise\n",
    "1. 保存模型参数的实际好处：\n",
    "    检查和分析模型：保存模型参数后，可以在训练完成后分析权重和偏置，研究模型的表现。\n",
    "    断点续训：可以在训练中断时保存当前模型参数，以便从中断处继续训练，节省时间。\n",
    "    实验再现性：保存模型参数可以确保在不同的时间点或不同的环境中重现同样的实验结果。\n",
    "    版本控制：可以在模型迭代过程中保存不同阶段的模型参数，以便对比和调优。\n",
    "2. 在不同架构中重用部分网络：\n",
    "    方法：可以先定义一个新的网络架构，然后将之前网络的前两层的参数加载到新网络中相应的部分。通过 state_dict 和 load_state_dict 可以实现参数部分加载。\n",
    "    实现：python\n",
    "        old_model = PreTrainedModel()  # 旧的预训练模型\n",
    "        new_model = NewModel()  # 新的模型架构\n",
    "        new_model.layer1.weight.data = old_model.layer1.weight.data  # 重用第一层的参数\n",
    "        new_model.layer2.weight.data = old_model.layer2.weight.data  # 重用第二层的参数\n",
    "    注意事项：需要确保新模型的层的输入输出维度与旧模型相匹配，否则会导致参数维度不兼容的问题。\n",
    "3. 保存方法：可以使用 torch.save() 将模型的结构代码和参数一起保存，或者保存模型的 state_dict（参数字典）和结构代码的独立文件。\n",
    "    限制：要确保模型架构兼容性，即在加载模型时需要确保模型代码能够正确解释保存的参数；例如，确保层数和顺序一致，输入输出维度匹配。\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
